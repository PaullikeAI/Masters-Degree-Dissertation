{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5838d26",
   "metadata": {},
   "source": [
    "#### Neural Network Data Training/Testing for Shield Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7983eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Formats time in seconds into hours/minutes/seconds and returns a string of the resulting time.\"\"\"\n",
    "    minutes = int(seconds // 60)\n",
    "    hours = int(minutes // 60)\n",
    "    minutes = minutes % 60\n",
    "    seconds = seconds % 60\n",
    "    if hours > 0:\n",
    "        return f\"{hours} hours, {minutes} minute{'s' if minutes != 1 else ''}, {seconds:.2f} seconds\"\n",
    "    if minutes > 0:\n",
    "        return f\"{minutes} minute{'s' if minutes != 1 else ''}, {seconds:.2f} seconds\"\n",
    "    return f\"{seconds:.2f} seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e29a7b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of experiences: 2951771\n",
      "Batch total:  604987\n",
      "Unsafe:  19441  - 3.21%\n",
      "Safe:  585546  - 96.79%\n",
      "\n",
      "Batch total:  549861\n",
      "Unsafe:  13559  - 2.47%\n",
      "Safe:  536302  - 97.53%\n",
      "\n",
      "Batch total:  457828\n",
      "Unsafe:  3769  - 0.82%\n",
      "Safe:  454059  - 99.18%\n",
      "\n",
      "Batch total:  453604\n",
      "Unsafe:  3788  - 0.84%\n",
      "Safe:  449816  - 99.16%\n",
      "\n",
      "Batch total:  450414\n",
      "Unsafe:  4301  - 0.95%\n",
      "Safe:  446113  - 99.05%\n",
      "\n",
      "Safe total: 2471836, 98.22%   Unsafe total: 44858, 1.78%\n"
     ]
    }
   ],
   "source": [
    "# Import the data.\n",
    "df = pd.read_csv(\"Shield_Experience_31.03.2025_13.41.csv\")\n",
    "print(f\"Number of experiences: {len(df)}\")\n",
    "\n",
    "# Split data into batches by sets of 20k. Last 20k episodes excluded, as will not train shield again at the end of training.\n",
    "Batch_1_1_to_20000 = df[df['Episode'].between(1, 20000 )]\n",
    "Batch_2_20001_to_40000 = df[df['Episode'].between(20001, 40000)]\n",
    "Batch_3_40001_to_60000 = df[df['Episode'].between(40001, 60000)]\n",
    "Batch_4_60001_to_80000 = df[df['Episode'].between(60001, 80000)]\n",
    "Batch_5_80001_to_100000 = df[df['Episode'].between(80001, 100000)]\n",
    "\n",
    "batches = [Batch_1_1_to_20000, Batch_2_20001_to_40000, Batch_3_40001_to_60000, Batch_4_60001_to_80000, Batch_5_80001_to_100000]\n",
    "\n",
    "saff = 0\n",
    "unsaff = 0\n",
    "for i in batches: # Check batch sizes.\n",
    "    print(\"Batch total: \", len(i))\n",
    "    \n",
    "    zeros = len(i[i['Safe'] == 0])\n",
    "    print(\"Unsafe: \", zeros,f\" - {zeros/len(i)*100:.2f}%\")\n",
    "    ones = len(i[i['Safe'] == 1])\n",
    "    saff += ones\n",
    "    unsaff += zeros\n",
    "    print(\"Safe: \", ones, f\" - {ones/len(i)*100:.2f}%\", end=\"\\n\\n\" )\n",
    "    # Safe and unsafe for each batch.\n",
    "\n",
    "print(f\"Safe total: {saff}, {saff/(saff+unsaff)*100:.2f}%   Unsafe total: {unsaff}, {unsaff/(saff+unsaff)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ccc046",
   "metadata": {},
   "source": [
    "###### Create Training/Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a18783b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  100000\n"
     ]
    }
   ],
   "source": [
    "# There will be one training batch made up of all five batches of episodes, due to the nature of testing many hyperparameters\n",
    "# in a grid search, the 5 steps and then using the average accuracy and recall as was done with Naive Bayes is too time consuming.\n",
    "last_20ks = []\n",
    "for b in batches:\n",
    "    # Append last 20,000 experiences in each batch to the training batch.\n",
    "    last_20ks.append(b.tail(20000))\n",
    "\n",
    "# Concatonate these to create the dataset to analyse network performace on.\n",
    "batch = pd.concat(last_20ks, ignore_index=True)\n",
    "print(\"Dataset size: \", len(batch))\n",
    "\n",
    "# Split into input data and targets.\n",
    "X = batch.drop(df.columns[[0, 1, 11]], axis=1) # Drop columns 0, 1 and 12 (index, episode, safe)\n",
    "Y = batch[\"Safe\"]\n",
    "\n",
    "# Split into Train and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=6)\n",
    "\n",
    "# Convert to a numpy array, then to a Tensor, with reshaping for the targets(Y_train and Y_test).\n",
    "numpy_array = X_train.values # First, convert to a Numpy array.\n",
    "X_train = torch.tensor(numpy_array, dtype=torch.float32)\n",
    "numpy_array = X_test.values\n",
    "X_test = torch.tensor(numpy_array, dtype=torch.float32)\n",
    "numpy_array = Y_train.values\n",
    "Y_train = torch.tensor(numpy_array, dtype=torch.float32).view(-1, 1)\n",
    "numpy_array = Y_test.values\n",
    "Y_test = torch.tensor(numpy_array, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b5753",
   "metadata": {},
   "source": [
    "##### Neural Network and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e492ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    \"\"\"Neural Network to act as a Binary classifier for shield safety.\"\"\"\n",
    "    def __init__(self, dropout_probability=0.3):\n",
    "        self.dropout = dropout_probability # Define dropout as a class atribute.\n",
    "        super(BinaryClassifier, self).__init__() # Binary classifier used.\n",
    "        self.hidden_layer_1 = nn.Linear(9, 64) # First hidden layer\n",
    "        if self.dropout:\n",
    "            self.dropout_layer_1 = nn.Dropout(p=self.dropout) # Dropout layer added if dropout active.\n",
    "        self.hidden_layer_2 = nn.Linear(64, 32) # Second hidden layer\n",
    "        if self.dropout:\n",
    "            self.dropout_layer_2 = nn.Dropout(p=self.dropout) # Second dropout layer added if dropout active.\n",
    "        self.output_layer = nn.Linear(32, 1) # Output layer\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid function\n",
    "        self.relu = nn.ReLU() # Relu function\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feed forward through the network\n",
    "        x = self.relu(self.hidden_layer_1(x))\n",
    "        if self.dropout:\n",
    "            x = self.dropout_layer_1(x)\n",
    "        x = self.relu(self.hidden_layer_2(x))\n",
    "        if self.dropout:\n",
    "            x = self.dropout_layer_2(x)\n",
    "        # Sigmoid function to output the probability of the experience being safe.\n",
    "        x = self.sigmoid(self.output_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5d04aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout: False\n",
      "Epoch 10, Loss: 0.0373\n",
      "Epoch 20, Loss: 0.0014\n",
      "Epoch 30, Loss: 0.0025\n",
      "Epoch 40, Loss: 0.0129\n",
      "Epoch 50, Loss: 0.0058\n",
      "Trained in 7 minutes, 56.09 seconds\n",
      "\n",
      "Threshold:  0.05\n",
      "Acc: 99.23%   Recall: 92.40% = 191.63\n",
      "Threshold:  0.1\n",
      "Acc: 99.23%   Recall: 96.00% = 195.23\n",
      "Threshold:  0.2\n",
      "Acc: 99.15%   Recall: 98.40% = 197.55\n",
      "Threshold:  0.3\n",
      "Acc: 99.03%   Recall: 98.40% = 197.43\n",
      "Threshold:  0.4\n",
      "Acc: 98.93%   Recall: 98.40% = 197.33\n",
      "Threshold:  0.46\n",
      "Acc: 98.91%   Recall: 98.80% = 197.70\n",
      "Threshold:  0.47\n",
      "Acc: 98.90%   Recall: 98.80% = 197.70\n",
      "Threshold:  0.48\n",
      "Acc: 98.89%   Recall: 98.80% = 197.69\n",
      "Threshold:  0.49\n",
      "Acc: 98.89%   Recall: 98.80% = 197.69\n",
      "Threshold:  0.5\n",
      "Acc: 98.88%   Recall: 98.80% = 197.68\n",
      "Threshold:  0.51\n",
      "Acc: 98.85%   Recall: 98.80% = 197.65\n",
      "Threshold:  0.52\n",
      "Acc: 98.83%   Recall: 98.80% = 197.63\n",
      "Threshold:  0.53\n",
      "Acc: 98.83%   Recall: 98.80% = 197.63\n",
      "Threshold:  0.54\n",
      "Acc: 98.81%   Recall: 98.80% = 197.61\n",
      "Threshold:  0.55\n",
      "Acc: 98.78%   Recall: 98.80% = 197.58\n",
      "Threshold:  0.6\n",
      "Acc: 98.69%   Recall: 99.20% = 197.88\n",
      "Threshold:  0.7\n",
      "Acc: 98.61%   Recall: 99.20% = 197.81\n",
      "Threshold:  0.8\n",
      "Acc: 98.39%   Recall: 99.60% = 198.00\n",
      "Threshold:  0.9\n",
      "Acc: 98.09%   Recall: 99.60% = 197.69\n",
      "Threshold:  0.95\n",
      "Acc: 97.76%   Recall: 100.00% = 197.75\n",
      "Threshold:  0.96\n",
      "Acc: 97.62%   Recall: 100.00% = 197.62\n",
      "Threshold:  0.97\n",
      "Acc: 97.45%   Recall: 100.00% = 197.44\n",
      "Threshold:  0.975\n",
      "Acc: 97.24%   Recall: 100.00% = 197.24\n",
      "Threshold:  0.985\n",
      "Acc: 96.90%   Recall: 100.00% = 196.90\n",
      "***************************************************************************************************************\n",
      "\n",
      "Dropout: 0.1\n",
      "Epoch 10, Loss: 0.1580\n",
      "Epoch 20, Loss: 0.0549\n",
      "Epoch 30, Loss: 0.0601\n",
      "Epoch 40, Loss: 0.0121\n",
      "Epoch 50, Loss: 0.0489\n",
      "Trained in 9 minutes, 44.65 seconds\n",
      "\n",
      "Threshold:  0.05\n",
      "Acc: 99.36%   Recall: 94.80% = 194.16\n",
      "Threshold:  0.1\n",
      "Acc: 99.13%   Recall: 97.60% = 196.73\n",
      "Threshold:  0.2\n",
      "Acc: 98.93%   Recall: 99.60% = 198.53\n",
      "Threshold:  0.3\n",
      "Acc: 98.77%   Recall: 99.60% = 198.36\n",
      "Threshold:  0.4\n",
      "Acc: 98.59%   Recall: 99.60% = 198.19\n",
      "Threshold:  0.46\n",
      "Acc: 98.52%   Recall: 99.60% = 198.12\n",
      "Threshold:  0.47\n",
      "Acc: 98.50%   Recall: 99.60% = 198.10\n",
      "Threshold:  0.48\n",
      "Acc: 98.50%   Recall: 99.60% = 198.10\n",
      "Threshold:  0.49\n",
      "Acc: 98.49%   Recall: 99.60% = 198.09\n",
      "Threshold:  0.5\n",
      "Acc: 98.48%   Recall: 99.60% = 198.09\n",
      "Threshold:  0.51\n",
      "Acc: 98.48%   Recall: 99.60% = 198.09\n",
      "Threshold:  0.52\n",
      "Acc: 98.48%   Recall: 99.60% = 198.08\n",
      "Threshold:  0.53\n",
      "Acc: 98.47%   Recall: 99.60% = 198.07\n",
      "Threshold:  0.54\n",
      "Acc: 98.47%   Recall: 99.60% = 198.07\n",
      "Threshold:  0.55\n",
      "Acc: 98.47%   Recall: 99.60% = 198.07\n",
      "Threshold:  0.6\n",
      "Acc: 98.44%   Recall: 99.60% = 198.04\n",
      "Threshold:  0.7\n",
      "Acc: 98.26%   Recall: 100.00% = 198.25\n",
      "Threshold:  0.8\n",
      "Acc: 97.95%   Recall: 100.00% = 197.96\n",
      "Threshold:  0.9\n",
      "Acc: 97.31%   Recall: 100.00% = 197.31\n",
      "Threshold:  0.95\n",
      "Acc: 96.58%   Recall: 100.00% = 196.58\n",
      "Threshold:  0.96\n",
      "Acc: 96.36%   Recall: 100.00% = 196.36\n",
      "Threshold:  0.97\n",
      "Acc: 95.97%   Recall: 100.00% = 195.98\n",
      "Threshold:  0.975\n",
      "Acc: 95.84%   Recall: 100.00% = 195.84\n",
      "Threshold:  0.985\n",
      "Acc: 95.52%   Recall: 100.00% = 195.52\n",
      "***************************************************************************************************************\n",
      "\n",
      "Dropout: 0.2\n",
      "Epoch 10, Loss: 0.0839\n",
      "Epoch 20, Loss: 0.0775\n",
      "Epoch 30, Loss: 0.0956\n",
      "Epoch 40, Loss: 0.0254\n",
      "Epoch 50, Loss: 0.0918\n",
      "Trained in 7 minutes, 36.74 seconds\n",
      "\n",
      "Threshold:  0.05\n",
      "Acc: 99.33%   Recall: 90.80% = 190.13\n",
      "Threshold:  0.1\n",
      "Acc: 99.29%   Recall: 92.80% = 192.09\n",
      "Threshold:  0.2\n",
      "Acc: 98.88%   Recall: 99.20% = 198.08\n",
      "Threshold:  0.3\n",
      "Acc: 98.71%   Recall: 99.60% = 198.31\n",
      "Threshold:  0.4\n",
      "Acc: 98.57%   Recall: 100.00% = 198.57\n",
      "Threshold:  0.46\n",
      "Acc: 98.47%   Recall: 100.00% = 198.47\n",
      "Threshold:  0.47\n",
      "Acc: 98.45%   Recall: 100.00% = 198.44\n",
      "Threshold:  0.48\n",
      "Acc: 98.41%   Recall: 100.00% = 198.40\n",
      "Threshold:  0.49\n",
      "Acc: 98.39%   Recall: 100.00% = 198.40\n",
      "Threshold:  0.5\n",
      "Acc: 98.34%   Recall: 100.00% = 198.34\n",
      "Threshold:  0.51\n",
      "Acc: 98.33%   Recall: 100.00% = 198.34\n",
      "Threshold:  0.52\n",
      "Acc: 98.33%   Recall: 100.00% = 198.33\n",
      "Threshold:  0.53\n",
      "Acc: 98.32%   Recall: 100.00% = 198.32\n",
      "Threshold:  0.54\n",
      "Acc: 98.32%   Recall: 100.00% = 198.32\n",
      "Threshold:  0.55\n",
      "Acc: 98.26%   Recall: 100.00% = 198.25\n",
      "Threshold:  0.6\n",
      "Acc: 98.16%   Recall: 100.00% = 198.16\n",
      "Threshold:  0.7\n",
      "Acc: 97.75%   Recall: 100.00% = 197.75\n",
      "Threshold:  0.8\n",
      "Acc: 97.42%   Recall: 100.00% = 197.42\n",
      "Threshold:  0.9\n",
      "Acc: 96.69%   Recall: 100.00% = 196.69\n",
      "Threshold:  0.95\n",
      "Acc: 95.72%   Recall: 100.00% = 195.72\n",
      "Threshold:  0.96\n",
      "Acc: 95.58%   Recall: 100.00% = 195.58\n",
      "Threshold:  0.97\n",
      "Acc: 95.23%   Recall: 100.00% = 195.24\n",
      "Threshold:  0.975\n",
      "Acc: 95.03%   Recall: 100.00% = 195.03\n",
      "Threshold:  0.985\n",
      "Acc: 94.41%   Recall: 100.00% = 194.40\n",
      "***************************************************************************************************************\n",
      "\n",
      "Dropout: 0.3\n",
      "Epoch 10, Loss: 0.1308\n",
      "Epoch 20, Loss: 0.0647\n",
      "Epoch 30, Loss: 0.2438\n",
      "Epoch 40, Loss: 0.2677\n",
      "Epoch 50, Loss: 0.0301\n",
      "Trained in 7 minutes, 18.01 seconds\n",
      "\n",
      "Threshold:  0.05\n",
      "Acc: 99.24%   Recall: 86.80% = 186.04\n",
      "Threshold:  0.1\n",
      "Acc: 98.94%   Recall: 95.20% = 194.13\n",
      "Threshold:  0.2\n",
      "Acc: 98.27%   Recall: 98.40% = 196.66\n",
      "Threshold:  0.3\n",
      "Acc: 97.71%   Recall: 99.60% = 197.31\n",
      "Threshold:  0.4\n",
      "Acc: 97.29%   Recall: 100.00% = 197.29\n",
      "Threshold:  0.46\n",
      "Acc: 96.95%   Recall: 100.00% = 196.95\n",
      "Threshold:  0.47\n",
      "Acc: 96.95%   Recall: 100.00% = 196.95\n",
      "Threshold:  0.48\n",
      "Acc: 96.94%   Recall: 100.00% = 196.94\n",
      "Threshold:  0.49\n",
      "Acc: 96.92%   Recall: 100.00% = 196.92\n",
      "Threshold:  0.5\n",
      "Acc: 96.88%   Recall: 100.00% = 196.88\n",
      "Threshold:  0.51\n",
      "Acc: 96.80%   Recall: 100.00% = 196.80\n",
      "Threshold:  0.52\n",
      "Acc: 96.78%   Recall: 100.00% = 196.78\n",
      "Threshold:  0.53\n",
      "Acc: 96.76%   Recall: 100.00% = 196.76\n",
      "Threshold:  0.54\n",
      "Acc: 96.71%   Recall: 100.00% = 196.72\n",
      "Threshold:  0.55\n",
      "Acc: 96.66%   Recall: 100.00% = 196.66\n",
      "Threshold:  0.6\n",
      "Acc: 96.58%   Recall: 100.00% = 196.57\n",
      "Threshold:  0.7\n",
      "Acc: 96.21%   Recall: 100.00% = 196.21\n",
      "Threshold:  0.8\n",
      "Acc: 95.53%   Recall: 100.00% = 195.53\n",
      "Threshold:  0.9\n",
      "Acc: 94.12%   Recall: 100.00% = 194.11\n",
      "Threshold:  0.95\n",
      "Acc: 92.92%   Recall: 100.00% = 192.93\n",
      "Threshold:  0.96\n",
      "Acc: 92.52%   Recall: 100.00% = 192.52\n",
      "Threshold:  0.97\n",
      "Acc: 92.05%   Recall: 100.00% = 192.06\n",
      "Threshold:  0.975\n",
      "Acc: 91.75%   Recall: 100.00% = 191.75\n",
      "Threshold:  0.985\n",
      "Acc: 90.95%   Recall: 100.00% = 190.95\n",
      "***************************************************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropouts = [False, 0.1, 0.2, 0.3] # Dropout probabilities tested (also no dropout when False)\n",
    "for d in dropouts:\n",
    "    print(\"Dropout:\", d)\n",
    "    # Create TensorDataset\n",
    "    # Combines the input features and labels into a dataset object compatible with DataLoader.\n",
    "    dataset = TensorDataset(X_train, Y_train)\n",
    "\n",
    "    # Create a weighted random sampler to give more weight to the class with fewer samples (unsafe)\n",
    "    class_counts = np.bincount(Y_train.squeeze().long()) # Count the number of instances of each class.\n",
    "    class_weights = 1.0 / torch.tensor(class_counts, dtype=torch.float) # Calculate class weights.\n",
    "    sample_weights = class_weights[Y_train.squeeze().long()] # Specify the weight for each sample.\n",
    "\n",
    "    # Initialise the DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=32, sampler=WeightedRandomSampler(weights=sample_weights, num_samples=len(Y_train), replacement=True))\n",
    "\n",
    "    # Initialise model, loss, and optimiser.\n",
    "    model = BinaryClassifier(d)\n",
    "    loss_ = nn.BCELoss() # Binary Cross-Entropy Loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    epochs = 50\n",
    "    t1 = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_(outputs, labels)\n",
    "            optimizer.zero_grad() # Zero gradients.\n",
    "            loss.backward() # Backpropagate through model.\n",
    "            optimizer.step() # Optimise model.\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "    t2 = time.time()\n",
    "    print(f\"Trained in {format_time(t2 - t1)}\", end=\"\\n\\n\")\n",
    "\n",
    "    thresholds = [0.05, 0.1, 0.2, 0.3, 0.4, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.975, 0.985] # Safe probability thresholds tested.\n",
    "    for th in thresholds:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_test)\n",
    "            Y_pred = (outputs >= th).float()\n",
    "\n",
    "        accuracy = accuracy_score(Y_test, Y_pred)\n",
    "        recall = recall_score(Y_test, Y_pred, pos_label=0)\n",
    "        print(\"Threshold: \", th)\n",
    "        print(f\"Acc: {accuracy*100:.2f}%   Recall: {recall*100:.2f}% = {(accuracy+recall)*100:.2f}\")\n",
    "\n",
    "    print(\"***************************************************************************************************************\", end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
